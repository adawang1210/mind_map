# pdf_processor.py
import os
import google.generativeai as genai

# ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ç²å– API é‡‘é‘°
gemini_key = "AIzaSyCVRn89Q4lURX5-Sy_Sdw-Ncv6zNEqbtEc"
genai.configure(api_key=gemini_key)
model = genai.GenerativeModel("gemini-1.5-pro")

# å®Œæ•´çš„ prompt
prompt = '''
ä½ æ˜¯ä¸€å€‹æ³•åœ‹æ­·å²å°ˆå®¶ï¼Œæˆ‘å°‡æä¾›ä¸€æ®µé—œæ–¼æ³•åœ‹æ­·å²çš„æ–‡ç»ï¼ˆå¯èƒ½æ˜¯æ–‡æœ¬ã€æ‘˜è¦æˆ– PDF å…§å®¹ï¼‰ï¼Œä½ çš„ä»»å‹™æ˜¯æ ¹æ“šä»¥ä¸‹è¦ç¯„æ€§æ¡†æ¶åˆ†æä¸¦æ¦‚æ‹¬å…¶å…§å®¹ï¼Œä¸¦å°‡åˆ†æçµæœä»¥æŒ‡å®šçš„ JSON æ ¼å¼è¼¸å‡ºã€‚å¦‚æœæ–‡ç»æ˜¯æ³•æ–‡ï¼Œè«‹ç›´æ¥æ ¹æ“šæ³•æ–‡åˆ†æä¸¦ç”¨ä¸­æ–‡å›è¦†ã€‚ä»¥ä¸‹æ˜¯åˆ†ææ¡†æ¶ï¼š

1. **ä¸»é¡Œå’Œè«–é»**
    - (1) ä¸»é¡Œï¼šæ–‡ç»æ¢è¨çš„ä¸»è¦ä¸»é¡Œæ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šæ–‡æ˜èˆ‡æ–‡åŒ–ã€æ”¿æ²»è®Šé©ï¼‰
    - (2) è«–é»ï¼šä½œè€…çš„æ ¸å¿ƒä¸»å¼µæˆ–è§€é»æ˜¯ä»€éº¼ï¼Ÿï¼ˆè¨»æ˜æ˜¯å¦å…·çˆ­è­°æ€§ï¼‰
    - (3) äº‹ä»¶ï¼šæ–‡ç»æåˆ°çš„é‡å¤§æ­·å²äº‹ä»¶æœ‰å“ªäº›ï¼Ÿï¼ˆåŒ…æ‹¬åç¨±ã€æ™‚é–“é»ã€é¡å‹ï¼‰
2. **èƒŒæ™¯èˆ‡æ™‚æœŸ**
    - (1) èƒŒæ™¯ï¼šæ–‡ç»æ¶‰åŠçš„æ­·å²èƒŒæ™¯æ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šç¤¾æœƒç’°å¢ƒã€åœ‹éš›å±€å‹¢ï¼‰
    - (2) æ™‚æœŸï¼šæ–‡ç»æ¶µè“‹çš„å…·é«”æ­·å²æ™‚æœŸæˆ–å¹´ä»£æ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šå…¬å…ƒå‰58å¹´è‡³å…¬å…ƒ472å¹´ï¼‰
3. **åœ°é»**
    - (1) åœ°ç†ï¼šæ–‡ç»æ¶‰åŠçš„å…·é«”åœ°é»æˆ–åœ°ç†ç¯„åœæ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šé«˜ç›§ã€èŠèŒµæ²³ï¼‰
4. **äººç‰©**
    - (1) æƒ…ç·’ï¼šåƒ…æ ¹æ“šæ–‡ç»å…§å®¹æå–äººç‰©çš„æƒ…æ„Ÿã€å‹•æ©Ÿæˆ–æ­·å²è©•åƒ¹ï¼Œä¸é€²è¡Œé¡å¤–æ¨æ¸¬æˆ–ä¸»è§€è§£è®€ï¼Œç¢ºä¿è³‡è¨Šç›´æ¥ä¾†è‡ªæ–‡æœ¬ã€‚
    - (2) åå­—ï¼šæ¶‰åŠå“ªäº›é‡è¦äººç‰©ï¼Ÿï¼ˆæä¾›å…¨åæˆ–ç¨±è™Ÿï¼‰
    - (3) åœ°ä½ï¼šé€™äº›äººç‰©çš„è§’è‰²æˆ–æ¬ŠåŠ›åœ°ä½æ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šè»äº‹é ˜è¢–ï¼‰
5. **çµ„ç¹”ï¼ˆæ”¿æ²»ã€è»äº‹æˆ–ç¤¾æœƒåœ˜é«”ï¼‰**
    - æ–‡ç»ä¸­æåˆ°çš„é—œéµçµ„ç¹”æ˜¯ä»€éº¼ï¼Ÿï¼ˆä¾‹å¦‚ï¼šç¾…é¦¬è»åœ˜ï¼Œè¨»æ˜é¡å‹èˆ‡åŠŸèƒ½ï¼‰
6. **æ¶‰åŠçš„æ ¸å¿ƒæ¦‚å¿µï¼ˆæŠ½è±¡åè©ï¼‰**
    - åƒ…å¾æ–‡ç»ä¸­æå–æœ€å¤šä¸‰å€‹åŸæ–‡æåŠçš„æŠ½è±¡æ¦‚å¿µï¼ˆä¾‹å¦‚ï¼šè‡ªç”±ã€å›ä¸»åˆ¶ï¼‰ï¼Œä¸é¡å¤–æ¨æ¸¬æˆ–å‰µé€ æ–°æ¦‚å¿µï¼Œç¢ºä¿æ¦‚å¿µæº–ç¢ºåæ˜ æ–‡ç»å…§å®¹ã€‚
7. **å½±éŸ¿å’Œæ„ç¾©**
    - æ–‡ç»æè¿°çš„æ­·å²ç™¼å±•å°æ³•åœ‹æœ‰ä»€éº¼å½±éŸ¿å’Œæ„ç¾©ï¼Ÿï¼ˆåˆ†ç‚ºçŸ­æœŸå½±éŸ¿ã€é•·æœŸæ„ç¾©)

**è«‹å‹™å¿…åªå›å‚³è¦æ±‚æ ¼å¼çš„å…§å®¹ï¼Œä¸è¦åŒ…å«é¡å¤–çš„æ–‡å­—æè¿°ã€‚**

**è¼¸å‡ºè¦æ±‚ï¼š**
- ä½ çš„å›ç­”**å¿…é ˆ**ç¬¦åˆä»¥ä¸‹ æ ¼å¼ï¼š

const nodeData = {
  topic: 'æ³•åœ‹æ­·å²åˆ†æ',
  id: 'history_root_001',
  style: { fontSize: '32', color: '#2c3e50', background: '#ecf0f1' },
  expanded: true,
  parent: null,
  tags: ['æ­·å²', 'æ³•åœ‹'],
  icons: ['ğŸ“œ'],
  children: [
    {
      topic: 'ä¸»é¡Œèˆ‡è«–é»',
      id: 'themes_arguments_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        { topic: 'ä¸»é¡Œ', id: 'themes_001', parent: 'themes_arguments_001', children: [], tags: ['æ–‡æ˜', 'æ”¿æ²»'] },
        { topic: 'è«–é»', id: 'arguments_001', parent: 'themes_arguments_001', children: [], hyperLink: '' },
        { topic: 'äº‹ä»¶', id: 'events_001', parent: 'themes_arguments_001', children: [], tags: ['é©å‘½', 'æˆ°çˆ­'] }
      ]
    },
    {
      topic: 'èƒŒæ™¯èˆ‡æ™‚æœŸ',
      id: 'context_period_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        { topic: 'èƒŒæ™¯', id: 'context_001', parent: 'context_period_001', children: [] },
        { topic: 'æ™‚æœŸ', id: 'period_001', parent: 'context_period_001', children: [] }
      ]
    },
    {
      topic: 'åœ°é»',
      id: 'location_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        { topic: 'åœ°ç†ç¯„åœ', id: 'geography_001', parent: 'location_001', children: [], tags: ['é«˜ç›§', 'å·´é»'] }
      ]
    },
    {
      topic: 'äººç‰©',
      id: 'characters_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        {
          topic: 'äººç‰©1',
          id: 'character_001',
          parent: 'characters_001',
          children: [
            { topic: 'è©•åƒ¹', id: 'eval_001', parent: 'character_001', children: [] },
            { topic: 'å§“å', id: 'name_001', parent: 'character_001', children: [] },
            { topic: 'åœ°ä½', id: 'status_001', parent: 'character_001', children: [] }
          ]
        }
      ]
    },
    {
      topic: 'çµ„ç¹”',
      id: 'organizations_001',
      expanded: true,
      parent: 'history_root_001',
      children: [], // å¯å‹•æ…‹æ·»åŠ å…·é«”çµ„ç¹”
      tags: ['è»åœ˜', 'æ”¿åºœ']
    },
    {
      topic: 'æ ¸å¿ƒæ¦‚å¿µ',
      id: 'concepts_001',
      expanded: true,
      parent: 'history_root_001',
      children: [], // å¯å‹•æ…‹æ·»åŠ æ¦‚å¿µ
      tags: ['è‡ªç”±', 'å›ä¸»åˆ¶']
    },
    {
      topic: 'å½±éŸ¿èˆ‡æ„ç¾©',
      id: 'impact_significance_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        { topic: 'çŸ­æœŸå½±éŸ¿', id: 'short_term_001', parent: 'impact_significance_001', children: [] },
        { topic: 'é•·æœŸæ„ç¾©', id: 'long_term_001', parent: 'impact_significance_001', children: [] }
      ]
    },
    {
      topic: 'æ€ç¶­å°åœ–å»ºè­°',
      id: 'mind_map_suggestion_001',
      expanded: true,
      parent: 'history_root_001',
      children: [
        { topic: 'ä¸»è»¸æ¦‚å¿µ', id: 'theme_suggestion_001', parent: 'mind_map_suggestion_001', children: [] },
        { topic: 'ç†ç”±', id: 'reason_001', parent: 'mind_map_suggestion_001', children: [] }
      ]
    }
  ]
};

'''

def analyze_french_history(pdf_files, prompt):
    contents = []
    for pdf_path in pdf_files:
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
        with open(pdf_path, "rb") as f:
            pdf_content = f.read()
        contents.append({"mime_type": "application/pdf", "data": pdf_content})
    
    response = model.generate_content(
        contents=[prompt] + contents
    )
    prompt_token = response.usage_metadata.prompt_token_count
    output_token = response.usage_metadata.candidates_token_count
    return response.text, prompt_token, output_token

def get_pdf_files_from_uploads(upload_folder="uploads"):
    if not os.path.exists(upload_folder):
        os.makedirs(upload_folder)
    pdf_files = [os.path.join(upload_folder, f) for f in os.listdir(upload_folder) if f.endswith('.pdf')]
    return pdf_files

if __name__ == "__main__":
    pdf_files = get_pdf_files_from_uploads()
    if not pdf_files:
        print("uploads è³‡æ–™å¤¾ä¸­ PDF æª”æ¡ˆ")
    else:
        response_text, prompt_token, output_token = analyze_french_history(pdf_files, prompt)
        print(response_text)
        print(f"Total prompt token count: {prompt_token}")
        print(f"Total output token count: {output_token}")